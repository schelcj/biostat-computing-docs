title:              Biostatistics Cluster Examples - R
css:                /css/sph.css
css:                /biostat/css/stylesheet.css
css:                /biostat/computing/overrides.css
xhtml header:       <link rel="stylesheet" type="text/css" href="/css/print.css" media="print" />
xhtml header:       <link rel="stylesheet" type="text/css" href="/css/mobile.css" media="handheld" />
breadcrumb:         sph|biostat|computing|cluster|examples
alt_formats:        txt

<!--#include virtual="/biostat/computing/header.shtml" -->

# R #
1. [Basic R Job][]
1. [Array job with R][]
1. [R array job with getenv()][]
1. [R array job with getopt()][]
1. [R with snow(fall)][]
1. [Snow/Snowfall node type SOCK][]
1. [Snow/Snowfall node type MPI][]

### Basic R Job ###
For the majority of your R work a simple batch script like below will suffice:
<script src="https://gist.github.com/2360874.js?file=gistfile1.sh"></script>
  
### Array job with R ###
[sarray][] provides the iteration of the array to the batch script via the __$SLURM_ARRAYID__
environment variable. This provides a means of changing the flow of your code, executing a different
R script, or setting variables in your code. A basic batch script that uses sarray to run multiple
R jobs:
<script src="https://gist.github.com/2360989.js?file=gistfile1.sh"></script>

### R array job with getenv() ###
To access the variable from within R simply use the *Sys.getenv()* function.
<script src="https://gist.github.com/2360044.js?file=gistfile1.r"></script>

### R array job with getopt() ###
To access the variable as a command line argugement 
<script src="https://gist.github.com/2360005.js?file=gistfile1.r"></script>

### R with snow(fall) ###

The snow and snowfall packages can be used in R to simplify the process of
writing parallel R scripts. These packages work by creating separate R processes
(slaves/nodes) and then sending jobs to those nodes in parellel. You have a
couple different options for communication between these nodes. The options are
communicationare [SOCKETS][], [MPI][], and [PVM][]. The biostatistics cluster does not implement
[PVM][] leaving you with a choice between [MPI][] and [SOCKETS][]. The basic difference between
the two is that [SOCKETS][] only allow communication within a single host and MPI
communicates across the network. When you submit a R job to the cluster using
snow/snowfall you should consider how many R cluster nodes you wish to start as
this will help you decide which type you need to use. You can think of the snow/snowfall
nodes as __1:1__ with cores and nodes, each node you start will use a single core.
If you need to start more slaves then a single cluster node has cores then you
will need to use MPI so those R slaves can communicate across the network.

Here are some examples of sbatch batch file for each type:

### Snow/Snowfall node type SOCK ###
This is a sample of initializing your cluster in snow and snowfall.
<script src="https://gist.github.com/2361085.js?file=gistfile1.r"></script>

This batch script requests a whole node be allocated to this job giving your
code up to 12 cores. This means you can start 12 snow/snowfall nodes within
your code. The key is the __--nodes=1-1__ option. This tells the scheduler
that you need exactly one whole node for your job with access to all the cores
in that node.
<script src="https://gist.github.com/2361123.js?file=gistfile1.sh"></script>

### Snow/Snowfall node type MPI ###
This is a sample of initializing your cluster in snow and snowfall.
<script src="https://gist.github.com/2361157.js?file=gistfile1.r"></script>

This batch script tells the scheduler that you would like to allocate 100
cpus(cores) to this single task, giving you 100 snow/snowfall nodes, that
it will run for one day and requires 2GB of memory. Two key things about this
patch script are the __--ntasks=100__ which is how you request those 100 cores
and that there is no __srun__ on the *R CMD BATCH* line. Do __NOT__ include srun
when using snow/snowfall and MPI. These libraries rely on Rmpi which will
handle starting the mpi session based on the environment that sbatch creates
for your job.
<script src="https://gist.github.com/2361175.js?file=gistfile1.r"></script>

<!--#include virtual="/biostat/computing/footer.shtml" -->

[SOCKETS]: http://en.wikipedia.org/wiki/Unix_domain_socket
[MPI]: http://en.wikipedia.org/wiki/Message_Passing_Interface
[PVM]: http://en.wikipedia.org/wiki/Parallel_Virtual_Machine
[sarray]: http://www.sph.umich.edu/biostat/computing/cluster/slurm.html#sarray
